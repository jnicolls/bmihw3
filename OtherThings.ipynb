{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and shit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import os \n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parent_dir = \"./data_fixed_crop_w_mask\"\n",
    "precomputed_path = \"features_matrix.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.8299998e-01  1.2056100e+05  5.4922956e-01  1.4699945e-01\n",
      "  2.7999999e-03  1.6000000e-03  5.3562564e-01  9.9140000e-01\n",
      "  9.9940002e-01  1.9901167e+02  1.4164154e+02  8.8326851e+01\n",
      " -1.4469041e+00  2.9172947e+03  7.8043795e-01  8.2708019e-01\n",
      "  1.2968200e+01  9.7119999e-01]\n"
     ]
    }
   ],
   "source": [
    "precomputed_df = pd.read_csv(precomputed_path)\n",
    "feature_names = list(precomputed_df)[1:]\n",
    "precomputed_fts = precomputed_df.values[:,1:]\n",
    "precomputed_fts =np.array(precomputed_fts,dtype=np.float32)\n",
    "print(precomputed_fts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do an initial zero-centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_fts -= np.mean(precomputed_fts, axis = 0)\n",
    "precomputed_fts /= np.std(precomputed_fts, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(precomputed_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4473657e-01 1.6824159e-01 9.1169290e-02 5.7367690e-02 5.6748547e-02\n",
      " 5.2320685e-02 3.6198188e-02 3.1822890e-02 2.2656877e-02 1.7601196e-02\n",
      " 9.3034180e-03 7.1804966e-03 2.3674807e-03 1.1376145e-03 8.7159796e-04\n",
      " 2.6753976e-04 6.5508975e-06 1.8152512e-06]\n",
      "[-0.33582258  0.3129383  -0.04206447 -0.01204051  0.31197217  0.3208049\n",
      "  0.00518964 -0.33550972 -0.30273733  0.21556541  0.16609216  0.02282244\n",
      "  0.00318173  0.30442756  0.21560022 -0.05786494  0.3394732   0.22484674]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = pca.transform(precomputed_fts)[:,:3]\n",
    "transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensionality(raw_data, new_dims=3):\n",
    "    pca = PCA()\n",
    "    pca.fit(raw_data)\n",
    "    print(\"variance explained by each principal component\")\n",
    "    print(pca.explained_variance_ratio_)  \n",
    "    print(\"the first principal component\")\n",
    "    print(pca.components_[0])\n",
    "    return pca.transform(precomputed_fts[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(paths):\n",
    "    data = []\n",
    "    label = []\n",
    "    name = []\n",
    "    for first_path in paths:\n",
    "        if first_path[0] == '.': # check for random dot files that come up :( )\n",
    "            continue\n",
    "        local_dir = os.path.join(data_parent_dir, first_path)\n",
    "        for image in os.listdir(local_dir):\n",
    "            hf = h5py.File(os.path.join(local_dir, image), 'r')\n",
    "            data.append(np.array(hf.get('data')))\n",
    "            label.append(np.array(hf.get('label')).item(0))\n",
    "            name.append(np.array(hf.get('name')))\n",
    "    d = {'pixel_data':data, 'label':label, 'name':name}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = os.listdir(data_parent_dir)\n",
    "image_df = get_image_features(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantics_path = \"mass_case_description_train_set.csv\"\n",
    "semantic_df = pd.read_csv(semantics_path)\n",
    "semantic_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1273 entries, 0 to 1317\n",
      "Data columns (total 13 columns):\n",
      "patient_id        1273 non-null object\n",
      "breast_density    1273 non-null int64\n",
      "side              1273 non-null object\n",
      "view              1273 non-null object\n",
      "abn_num           1273 non-null int64\n",
      "mass_shape        1273 non-null object\n",
      "mass_margins      1273 non-null object\n",
      "assessment        1273 non-null int64\n",
      "pathology         1273 non-null object\n",
      "subtlety          1273 non-null int64\n",
      "od_img_path       1273 non-null object\n",
      "od_crop_path      1273 non-null object\n",
      "mask_path         1273 non-null object\n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 139.2+ KB\n"
     ]
    }
   ],
   "source": [
    "semantic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_feature_names = ['breast_density', 'abn_num', 'mass_shape', 'mass_margins', 'assessment']\n",
    "semantic_label_name = ['pathology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' '3' '4']\n",
      "['1' '2' '3' '4' '5' '6']\n",
      "['ARCHITECTURAL_DISTORTION' 'ASYMMETRIC_BREAST_TISSUE'\n",
      " 'FOCAL_ASYMMETRIC_DENSITY' 'IRREGULAR'\n",
      " 'IRREGULAR-ARCHITECTURAL_DISTORTION' 'IRREGULAR-FOCAL_ASYMMETRIC_DENSITY'\n",
      " 'LOBULATED' 'LOBULATED-ARCHITECTURAL_DISTORTION' 'LOBULATED-IRREGULAR'\n",
      " 'LOBULATED-LYMPH_NODE' 'LOBULATED-OVAL' 'LYMPH_NODE' 'OVAL'\n",
      " 'OVAL-LYMPH_NODE' 'ROUND' 'ROUND-IRREGULAR-ARCHITECTURAL_DISTORTION'\n",
      " 'ROUND-LOBULATED' 'ROUND-OVAL']\n",
      "['CIRCUMSCRIBED' 'CIRCUMSCRIBED-ILL_DEFINED'\n",
      " 'CIRCUMSCRIBED-MICROLOBULATED' 'CIRCUMSCRIBED-OBSCURED' 'ILL_DEFINED'\n",
      " 'ILL_DEFINED-SPICULATED' 'MICROLOBULATED' 'MICROLOBULATED-ILL_DEFINED'\n",
      " 'MICROLOBULATED-ILL_DEFINED-SPICULATED' 'MICROLOBULATED-SPICULATED'\n",
      " 'OBSCURED' 'OBSCURED-ILL_DEFINED' 'OBSCURED-ILL_DEFINED-SPICULATED'\n",
      " 'OBSCURED-SPICULATED' 'SPICULATED']\n",
      "['0' '1' '2' '3' '4' '5']\n"
     ]
    }
   ],
   "source": [
    "for feature in semantic_feature_names:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    #print(semantic_df[feature].values)\n",
    "    #print(semantic_df[semantic_df[feature].isnull() == True])\n",
    "    le.fit(list(semantic_df[feature].astype(str)))\n",
    "    print(le.classes_)\n",
    "    semantic_df[feature] = le.transform(semantic_df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(semantic_df[semantic_feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  4  0 ... 14  3  3]\n"
     ]
    }
   ],
   "source": [
    "print(semantic_df[semantic_feature_names[2]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
