{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI 260 ASSIGNMENT #3 | Mammogram Spring 2018\n",
    "\n",
    "## Name 1:Joseph Nicolls\n",
    "\n",
    "## Name 2: Alex Lu\n",
    "\n",
    "Breast cancer has the highest incidence and second highest mortality rate for women in the US. \n",
    "Your task is to utilize machine learning to either classify AND/OR segment mammograms or neither, as long as you justify why it is useful to do whatever it is you want to do. If someone turns in a deep dream assignment using mammograms this might be amusing, but not so useful to patients. Consider this a mini-project, we highly suggest you work with 1 other person, it can be someone in your team. \n",
    "\n",
    "In addition to the mammograms, the dataset includes segmentations and mass_case_description_train_set.csv, which contains information about the mass shape, mass margins, assessment number, pathology diagnosis, and subtlety. Take some time to research what all of these different fields mean and whether you can use them in your algorithm or not. You dont need to use all of what is provided to you. \n",
    "\n",
    "Some ideas:\n",
    "\n",
    "1. use the ROIâ€™s or segmentations to extract features, and then train a classifier based on those features using the algorithms presented to you in the machine learning lectures, does not need to be deep learning. \n",
    "\n",
    "2. use convolutional neural networks, feel free to use any of the code we went over in class or use your own (custom code, sklearn, keras, Tensorflow etc.). If you dont want to place helper functions and classes into this notebook, place them in a .py file in the same folder called helperfunctions.py and import them into this notebook. \n",
    "\n",
    "The data is here:\n",
    "\n",
    "https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM\n",
    "\n",
    "If you do not like python, you can use a different language and turn your assignment in as a folder with all your code, a folder with all your figures and a latex or doc file with the writeup. The writeup doesnt need to be long, 1 page will do and cite at least one clinical paper and one technical paper. If you like python please place the writeup and code into this notebook. Use the markdown to tell is what you are doing in each section. You will not be graded on the performance of your model, only the scientific soundness of your claims, methodology, evaluation (ie fair but insightful statistics) and discussion of the shortcomings of what you tried. \n",
    "\n",
    "The format for this homework is as follows:\n",
    "\n",
    "1. Describe what you are doing and why it matters to patients using at least one citation\n",
    "\n",
    "2. Describe the relevant statistics of the data, how were the images taken ? how were they labeled ? what is the class balance and majority classifier accuracy ? How will you divide the data into testing, training and validation.\n",
    "\n",
    "3. Describe your data pipeline, ie how is the data scrubbed, normalized, stored and fed to the model for training. \n",
    "\n",
    "4. Explain how the model you chose works along side the code for it and at least one technical citation to give credit where credit is due. \n",
    "\n",
    "5. There are many ways to do training, take us through how you do it. (ie we used early stopping and we decided when to stop based on validation loss)  \n",
    "\n",
    "6. Make a figure displaying your results\n",
    "\n",
    "7. Discuss pros and cons of your method and what you might have done differently now that youve tried or would try if you had more time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional ML techniques for Classification of Mammograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Approach and Relevance\n",
    "\n",
    "Mammograms are difficult to classify because identifying features for malignant tumors can be vague and masses in mammograms can appear anywhere with any orientation in the breast tissue. Though the setup for this problem suggests use of CNNs, we want to use traditional ML techniques in this exploratory research for a variety of reasons. The principal reason that we want to do this is for the feature analysis possible with traditional ML technqiues that isn't possible with CNNs. According to a study from Britton et. all, sensitivity of radiologists in classifying mammograms can vary between 53.1-74.1%. Through feature analysis, indiciative features could be highlighted for radiologists to focus on, potentially raising sensitivites and decreasing the variability of senestivities between radiologists. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images were taken from the Digital Database for Screening Mammography (DDSM), a database which consists of 2620 mammogram studies. These images are X-rays, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try to leverage the following features in order to make attempts at classification: \n",
    "* features in the features_matrix.csv (ASM, Area, Centroid coordinates, ...) \n",
    "\n",
    "We initially predict some potential issues with this approach: the number of features is large, and many are potentially correlated. Let's try to do some PCA on this data to figure out which features seem important "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the packages that we're going to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining global variables for paths, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parent_dir = \"./data_fixed_crop_w_mask\"\n",
    "precomputed_path = \"features_matrix.csv\"\n",
    "validation_prop = .1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(paths):\n",
    "    data = []\n",
    "    label = []\n",
    "    name = []\n",
    "    for first_path in paths:\n",
    "        if first_path[0] == '.': # check for random dot files that come up :( )\n",
    "            continue\n",
    "        local_dir = os.path.join(data_parent_dir, first_path)\n",
    "        for image in os.listdir(local_dir):\n",
    "            hf = h5py.File(os.path.join(local_dir, image), 'r')\n",
    "            data.append(np.array(hf.get('data')))\n",
    "            label.append(np.array(hf.get('label')))\n",
    "            name.append(np.array(hf.get('name')))\n",
    "    d = {'pixel_data':data, 'label':label, 'name':name}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \n",
    "    # reading things in \n",
    "    all_paths = os.listdir(data_parent_dir)\n",
    "    image_df = get_image_features(all_paths)\n",
    "    precomputed_df = pd.read_csv(precomputed_path)\n",
    "\n",
    "    # zero-centering, normalization\n",
    "    precomputed_fts = precomputed_df.values[:,1:]\n",
    "    precomputed_fts = np.array(precomputed_fts,dtype=np.float32)   \n",
    "    precomputed_fts -= np.mean(precomputed_fts, axis = 0)\n",
    "    precomputed_fts /= np.std(precomputed_fts, axis=0)\n",
    "    \n",
    "    # adding back to df \n",
    "    feature_names = list(precomputed_df)[1:]\n",
    "    precomputed_df[feature_names] = precomputed_fts\n",
    "    \n",
    "    # joining dfs\n",
    "    df = image_df.join(precomputed_df)\n",
    "\n",
    " #   feature_names.append(\"pixel_data\")\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "    return train, test, feature_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train,feature_names):\n",
    "    lassoClf = Lasso()\n",
    "    lassoClf.fit(train[feature_names], train['label'].astype('int'))\n",
    "    \n",
    "    svcClf = SVC()\n",
    "    svcClf.fit(train[feature_names], train['label'].astype('int'))\n",
    "    \n",
    "    rfClf = RandomForestClassifier()\n",
    "    rfClf.fit(train[feature_names], train['label'].astype('int'))\n",
    "    \n",
    "    return [lassoClf, svcClf, rfClf]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_models(models, test, feature_names):\n",
    "    for model in models:\n",
    "        y_true = test['label'].astype('int')\n",
    "        y_pred = model.predict(test[feature_names])\n",
    "        print(\"auroc: \" +  str(roc_auc_score(y_true, y_pred)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    train, test, feature_names = preprocess()\n",
    "    models = train_models(train, feature_names)\n",
    "    validate_models(models, test, feature_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc: 0.5\n",
      "auroc: 0.44826828410689173\n",
      "auroc: 0.48430907172995774\n"
     ]
    }
   ],
   "source": [
    "pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Britton P, Warwick J, Wallis MG, et al. Measuring the accuracy of diagnostic imaging in symptomatic breast patients: team and individual performance. The British Journal of Radiology. 2012;85(1012):415-422. doi:10.1259/bjr/32906819."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
